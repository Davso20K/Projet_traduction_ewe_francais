# Traducteur et Reconnaissance Vocale (√âw√© & Gegbe)

Ce projet vise √† d√©velopper une solution compl√®te de reconnaissance vocale et de traduction pour les langues **√âw√©** et **Gegbe (Mina)** (langues vernaculaires parl√©es principalement au Togo, au Ghana et au B√©nin). L'objectif final est de permettre la conversion de la parole en texte (Speech-to-Text) et la traduction bidirectionnelle entre ces langues et le Fran√ßais ou l'Anglais, le tout via une interface graphique intuitive.

**Membres du groupe**
- AFOMALE David
- DOGBO Sarah
- BOTRE Aboudou
- TEPE Paulin
- NOYOULIWA Victoire

## ‚ú® Fonctionnalit√©s Cl√©s Impl√©ment√©es

Le projet int√®gre nativement les trois piliers suivants, fonctionnels et test√©s :

### 1. üéôÔ∏è Reconnaissance Vocale (ASR Unifi√©)
-   **Objectif** : Convertir la parole (Mina ou √âw√©) en texte brut.
-   **Technologie** : Mod√®le **OpenAI Whisper** (architecture Transformer).
-   **Impl√©mentation** : 
    -   Nous utilisons une approche unifi√©e o√π le mod√®le est capable de transcrire les deux langues.
    -   Entra√Ænement optimis√© pour CPU via le script `src/models/train_whisper_cpu.py`.
    -   **Donn√©es** : Le mod√®le est entra√Æn√© sur **notre propre corpus biblique** constitu√© localement par nos scrapers. Il combine :
        -   Audio/Texte **√âw√©** (Bible compl√®te).
        -   Audio/Texte **Gegbe** (Bible compl√®te).
        -   Ces donn√©es sont fusionn√©es dans `data/processed/bible_asr_dataset.csv`.

### 2. üîÑ Cha√Æne de Traduction en Cascade (Pivot Strategy)
Une architecture sophistiqu√©e en deux temps pour pallier le manque de donn√©es directes Mina-Fran√ßais :
-   **√âtape A : Mina ‚ûî √âw√© (Normalisation)**
    -   **Mod√®le** : `facebook/nllb-200` (No Language Left Behind).
    -   **R√¥le** : Utilise l'√âw√© comme langue pivot standardis√©e. Le mod√®le est capable de comprendre le Mina (proche dialectalement) et de le reformuler en √âw√© √©crit standard.
-   **√âtape B : √âw√© ‚ûî Fran√ßais (Traduction Finale)**
    -   **Mod√®le** : `Helsinki-NLP/opus-mt-ee-fr`.
    -   **R√¥le** : Mod√®le de traduction neuronale sp√©cialis√© (NMT) qui assure une haute qualit√© linguistique vers le fran√ßais.

### 3. ‚ö° Optimisation CPU & Inf√©rence
Le projet est con√ßu pour tourner sur des machines sans GPU (ex: laptops √©tudiants) :
-   **CTranslate2** : Moteur d'inf√©rence ultra-rapide int√©gr√© pour le mod√®le NMT (`src/models/translation_ewe_fr.py`). Il permet une ex√©cution 2x √† 4x plus rapide qu'un mod√®le PyTorch standard sur CPU.
-   **Quantification INT8** : R√©duction de la pr√©cision des poids (de 32 bits √† 8 bits) pour diviser par 4 la consommation m√©moire sans perte notable de qualit√©.
-   **Ready-to-use** : L'infrastructure supporte l'ajout futur de `faster-whisper` pour la partie vocale.

## Vision du Projet

Le syst√®me final offrira les fonctionnalit√©s suivantes :
1.  **Reconnaissance Vocale (ASR) :** Conversion de fichiers audio Mina/√âw√© en texte via un mod√®le Whisper unifi√©.
2.  **Cha√Æne de Traduction en Cascade :**
    -   Mina ‚ûî √âw√© (Adaptation dialectale via NLLB fine-tun√©).
    -   √âw√© ‚ûî Fran√ßais / Autre (via Helsinki-NLP Opus-MT).
3.  **Optimisation CPU :** Utilisation de la quantification **INT8**, **faster-whisper** et **CTranslate2** pour garantir des performances fluides sur du mat√©riel grand public (CPU).
4.  **Interface Graphique (GUI) :** Application interactive pour la saisie audio/texte et l'affichage des traductions.

## Architecture & Logique du Mod√®le

Ce syst√®me repose sur une **architecture en cascade** (Cascaded Architecture) compos√©e de trois intelligences artificielles distinctes qui communiquent entre elles pour r√©aliser la t√¢che finale.

### Le Flux de Donn√©es
1.  **Entr√©e** : Audio (Parole en Mina ou √âw√©).
2.  **Transcription (ASR)** : Le son est converti en texte Mina/√âw√©.
3.  **Pivot (Si n√©cessaire)** : Si la langue source est le Mina, le texte est traduit vers l'√âw√©.
4.  **Traduction Finale (NMT)** : Le texte √âw√© est traduit en Fran√ßais.

### Les Mod√®les Composants

#### 1. ASR - Reconnaissance Vocale (`openai/whisper`)
-   **R√¥le** : Convertir l'audio en texte.
-   **Mod√®le** : Nous utilisons **OpenAI Whisper (Base/Small)**, fine-tun√© sur notre corpus biblique local.
-   **Lien avec le code** : G√©r√© par `src/models/train_whisper_cpu.py`.
-   **Importance** : C'est la "bouche" du syst√®me. Sans lui, impossible de traiter la parole. Nous l'avons optimis√© pour le CPU en gelant 90% de ses param√®tres durant l‚Äôentra√Ænement.

#### 2. Pivot - Adaptation Dialectale (`facebook/nllb-200`)
-   **R√¥le** : Combler le foss√© entre le Mina et l'√âw√©.
-   **Mod√®le** : **NLLB-200 (No Language Left Behind)** de Meta.
-   **Logique** : Le Mina manque de ressources directes vers le fran√ßais. L'√âw√© √©tant une langue s≈ìur tr√®s proche avec plus de ressources, nous utilisons NLLB pour "normaliser" le Mina en √âw√© standard.
-   **Lien avec le code** : Impl√©ment√© dans `src/models/translation_mina_ewe.py`.

#### 3. NMT - Traduction Finale (`Helsinki-NLP/opus-mt-ee-fr`)
-   **R√¥le** : Traduire le texte √âw√© vers le Fran√ßais.
-   **Mod√®le** : **OPUS-MT** de l'Universit√© d'Helsinki.
-   **Importance** : C'est le mod√®le sp√©cialis√© qui conna√Æt la grammaire fran√ßaise. Il assure la fluidit√© de la sortie finale.
-   **Lien avec le code** : Utilis√© dans `src/models/translation_ewe_french.py`.

### Orchestration (`TranslationCascade`)
Le fichier `src/pipeline/translate_cascade.py` est le chef d'orchestre. Il initialise les trois mod√®les et fait passer les donn√©es de l'un √† l'autre de mani√®re transparente pour l'utilisateur.

### ‚ùì Pourquoi cette architecture complexe ?

Pourquoi ne pas faire simplement **Audio Mina ‚ûî Texte Fran√ßais** ?

1.  **Manque de Donn√©es (Low-Resource)** : Il n'existe pas de dataset massif de type "Audio Mina ‚Üî Texte Fran√ßais" pour entra√Æner une IA directe.
2.  **La Strat√©gie Pivot** : Nous disposons de la Bible en Mina et en √âw√©. Comme ces langues sont tr√®s proches, nous pouvons traduire le Mina en √âw√© (plus riche en ressources).
3.  **Le R√¥le de l'ASR** : L'ASR est **indispensable**. C'est le seul moyen de passer du monde sonore au monde textuel. Sans lui, les mod√®les de traduction (qui ne lisent que du texte) seraient inutilisables pour une application vocale.

## Structure du Projet (Code)

```text
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                # Donn√©es brutes de scraping
‚îÇ   ‚îú‚îÄ‚îÄ processed/          # Corpus parall√®le align√© (Mina/√âw√©)
‚îú‚îÄ‚îÄ models/                 # Stockage local des mod√®les (Whisper, NLLB, OPUS)
‚îú‚îÄ‚îÄ notebooks/              # Travaux d'exp√©rimentation
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ config/             # Hyperparam√®tres (batch size, freeze, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ models/             # C'est ici que vivent les mod√®les :
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_whisper_cpu.py    # Entra√Ænement ASR
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ translation_mina_ewe.py # Logique du Pivot (NLLB)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ translation_ewe_french.py # Logique NMT Finale
‚îÇ   ‚îú‚îÄ‚îÄ pipeline/           # Orchestration (translate_cascade.py)
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing/      # Alignement et nettoyage de corpus
‚îÇ   ‚îî‚îÄ‚îÄ scraping/           # Scripts de collecte Bible
‚îî‚îÄ‚îÄ requirements.txt        # D√©pendances Python
```

## √âtat d'avancement technique

## Installation

### 1. Pr√©requis
- Python 3.8+
- Biblioth√®ques additionnelles (voir `requirements.txt`)

### 2. Mise en place
```bash
# Cr√©er et activer l'environnement virtuel
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate

# Installer les d√©pendances (IMPORTANT)
pip install -r requirements.txt
```

## Guide d'Utilisation (Pas-√†-pas)

Pour mener √† bien le projet de la collecte √† la traduction finale, suivez ces √©tapes dans l'ordre :

### √âtape 1 : Collecte des donn√©es
Lancez le scraper pour r√©cup√©rer les textes et audios des bibles √âw√© et Mina.
```bash
python -m src.pipeline.build_corpus
```
*Cette √©tape cr√©e aussi automatiquement le fichier d'alignement `data/processed/parallel_mina_ewe.csv`.*

### √âtape 2 : Pr√©paration du Dataset ASR
Ouvrez et ex√©cutez le notebook **`notebooks/02_prepare_asr_dataset.ipynb`**. 
- Il convertira les audios en WAV 16kHz.
- Il nettoiera les textes.
- Il g√©n√©rera le dataset final pour l'entra√Ænement.

### √âtape 3 : Entra√Ænement Local (CPU)
Ouvrez le notebook **`notebooks/03_train_whisper_ewe.ipynb`**.
- Il appelle le module `src.models.train_whisper_cpu`.
- Vous pouvez y modifier les hyperparam√®tres (gel des couches, batch size) et suivre l'avancement de l'apprentissage ASR.

### √âtape 4 : Traduction Finale (Cascade)
Utilisez le m√™me notebook ou le terminal pour tester la cha√Æne compl√®te :
```bash
python -m src.pipeline.translate_cascade
```
*Le syst√®me prendra une phrase en Mina, la pivotera en √âw√©, puis la traduira en Fran√ßais.*

## Configuration du Mat√©riel
Le projet est optimis√© pour tourner sur **CPU uniquement**. 
- Inf√©rence : **INT8** via CTranslate2/faster-whisper.
- Entra√Ænement : **Param√®tres gel√©s √† 90%** pour √©conomiser la RAM et le processeur.


## Auteur
**AFOMALE Komi David Frank**
Cours : MTH2321

---
*Ce projet est r√©alis√© dans un cadre acad√©mique et de recherche pour la promotion des langues vernaculaires √† travers les technologies de l'IA.*
