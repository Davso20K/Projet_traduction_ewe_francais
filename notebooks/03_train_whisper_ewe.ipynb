{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "d18cb3d5",
            "metadata": {},
            "source": [
                "# √âtape 3 : Entra√Ænement et Test de la Cascade de Traduction\n",
                "\n",
                "Ce notebook permet de lancer l'entra√Ænement ASR (Speech-to-Text) sur CPU et de tester la cha√Æne de traduction finale (Mina ‚ûî √âw√© ‚ûî Fran√ßais)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "5b26b6cf",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\EPL\\MTH2321\\MTH_2321_APEKE\\Projet_traduction_ewe_francais\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "import importlib\n",
                "from pathlib import Path\n",
                "if str(Path.cwd().parent) not in sys.path:\n",
                "    sys.path.append(str(Path.cwd().parent))\n",
                "\n",
                "import pandas as pd\n",
                "import torch\n",
                "import torchaudio\n",
                "from transformers import WhisperForConditionalGeneration, WhisperProcessor, AutoTokenizer, AutoModelForSeq2SeqLM, MarianTokenizer, MarianMTModel\n",
                "from src.config import settings\n",
                "import src.models.train_whisper_cpu\n",
                "\n",
                "# Reload de nos modules persos\n",
                "import src.models.translation_mina_ewe\n",
                "import src.models.translation_ewe_fr\n",
                "import src.pipeline.translate_cascade\n",
                "importlib.reload(src.models.train_whisper_cpu)\n",
                "importlib.reload(src.models.translation_mina_ewe)\n",
                "importlib.reload(src.models.translation_ewe_fr)\n",
                "importlib.reload(src.pipeline.translate_cascade)\n",
                "\n",
                "from src.models.train_whisper_cpu import train_whisper_on_cpu\n",
                "from src.pipeline.translate_cascade import TranslationCascade"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a1",
            "metadata": {},
            "source": [
                "## 1. Entra√Ænement ASR (Whisper sur CPU)\n",
                "\n",
                " (> **Note :** L'entra√Ænement sur CPU est lent. Nous utilisons un gel des couches (freeze) √† 90% pour acc√©l√©rer le processus. Les hyperparam√®tres sont configur√©s dans `src/config/settings.py`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "a2",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Dataset charg√© : 801 exemples.\n",
                        "--- Initialisation Entra√Ænement Whisper (openai/whisper-base) ---\n",
                        "Chargement du dataset depuis C:\\EPL\\MTH2321\\MTH_2321_APEKE\\Projet_traduction_ewe_francais\\data\\processed\\bible_asr_dataset.csv...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Generating train split: 801 examples [00:00, 5634.39 examples/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Pr√©paration du dataset (Audio -> Mel Spectrogram + Tokenization)...\n",
                        "Dataset keys before map: dict_keys(['train'])\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 801/801 [01:31<00:00,  8.79 examples/s]\n",
                        "c:\\EPL\\MTH2321\\MTH_2321_APEKE\\Projet_traduction_ewe_francais\\venv\\Lib\\site-packages\\transformers\\training_args.py:1636: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of ü§ó Transformers. Use `use_cpu` instead\n",
                        "  warnings.warn(\n",
                        "c:\\EPL\\MTH2321\\MTH_2321_APEKE\\Projet_traduction_ewe_francais\\src\\models\\train_whisper_cpu.py:158: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
                        "  trainer = Seq2SeqTrainer(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Dataset type after map: <class 'datasets.dataset_dict.DatasetDict'>\n",
                        "Dataset keys after map: dict_keys(['train'])\n",
                        "Mod√®le de 72593920 params. Gel de 90.0% pour CPU...\n",
                        "ATTENTION: 'test' split manquant. Keys actuels : dict_keys(['train'])\n",
                        "Tentative de split de secours...\n",
                        "Mise √† jour des keys : dict_keys(['train', 'test'])\n",
                        "D√©marrage de l'entra√Ænement...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "You're using a WhisperTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "\n",
                            "    <div>\n",
                            "      \n",
                            "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                            "      [20/20 06:31, Epoch 0/1]\n",
                            "    </div>\n",
                            "    <table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            " <tr style=\"text-align: left;\">\n",
                            "      <th>Step</th>\n",
                            "      <th>Training Loss</th>\n",
                            "      <th>Validation Loss</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <td>10</td>\n",
                            "      <td>4.797400</td>\n",
                            "      <td>4.315985</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>20</td>\n",
                            "      <td>4.099200</td>\n",
                            "      <td>3.867604</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table><p>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\EPL\\MTH2321\\MTH_2321_APEKE\\Projet_traduction_ewe_francais\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:3918: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
                        "  warnings.warn(\n",
                        "There were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Entra√Ænement termin√©.\n",
                        "Exportation du mod√®le ASR vers C:\\EPL\\MTH2321\\MTH_2321_APEKE\\Projet_traduction_ewe_francais\\models\\whisper-ewe-mina-final...\n",
                        "Mod√®le ASR export√© avec succ√®s !\n"
                    ]
                }
            ],
            "source": [
                "# Chargement du dataset pr√©par√© √† l'√©tape 2\n",
                "dataset_path = settings.PROCESSED_DIR / \"bible_asr_dataset.csv\"\n",
                "\n",
                "if dataset_path.exists():\n",
                "    df = pd.read_csv(dataset_path)\n",
                "    print(f\"Dataset charg√© : {len(df)} exemples.\")\n",
                "    \n",
                "    # Lancement de l'initialisation de l'entra√Ænement\n",
                "    # Note: assurez-vous d'avoir assez de RAM\n",
                "    model, processor = train_whisper_on_cpu(None) \n",
                "    \n",
                "    # --- SAUVEGARDE DU MOD√àLE ENTRA√éN√â (EXPORT) ---\n",
                "    export_dir = settings.PROJECT_ROOT / \"models\" / \"whisper-ewe-mina-final\"\n",
                "    print(f\"Exportation du mod√®le ASR vers {export_dir}...\")\n",
                "    model.save_pretrained(export_dir)\n",
                "    processor.save_pretrained(export_dir)\n",
                "    print(\"Mod√®le ASR export√© avec succ√®s !\")\n",
                "else:\n",
                "    print(\"Erreur : Le dataset ASR n'a pas encore √©t√© g√©n√©r√©. Veuillez ex√©cuter le notebook 02 d'abord.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a2_export",
            "metadata": {},
            "source": [
                "## 2. Exportation des autres mod√®les (NLLB et Opus-MT)\n",
                "\n",
                "Pour avoir une solution 100% autonome, nous t√©l√©chargeons et sauvegardons localement les mod√®les de traduction."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "a2_export_code",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "T√©l√©chargement et export des mod√®les de traduction...\n",
                        "Mod√®le NLLB d√©j√† pr√©sent dans C:\\EPL\\MTH2321\\MTH_2321_APEKE\\Projet_traduction_ewe_francais\\models\\nllb-mina-ewe-local\n",
                        "Mod√®le Opus d√©j√† pr√©sent dans C:\\EPL\\MTH2321\\MTH_2321_APEKE\\Projet_traduction_ewe_francais\\models\\opus-ewe-fr-local\n",
                        "Tous les mod√®les sont pr√™ts localement !\n"
                    ]
                }
            ],
            "source": [
                "print(\"T√©l√©chargement et export des mod√®les de traduction...\")\n",
                "\n",
                "# 1. Export NLLB (Mina -> Ewe)\n",
                "nllb_model_name = \"facebook/nllb-200-distilled-600M\"\n",
                "nllb_path = settings.PROJECT_ROOT / \"models\" / \"nllb-mina-ewe-local\"\n",
                "\n",
                "if not nllb_path.exists():\n",
                "    print(f\"T√©l√©chargement de {nllb_model_name}...\")\n",
                "    tokenizer = AutoTokenizer.from_pretrained(nllb_model_name)\n",
                "    model = AutoModelForSeq2SeqLM.from_pretrained(nllb_model_name)\n",
                "    \n",
                "    print(f\"Sauvegarde dans {nllb_path}...\")\n",
                "    model.save_pretrained(nllb_path)\n",
                "    tokenizer.save_pretrained(nllb_path)\n",
                "else:\n",
                "    print(f\"Mod√®le NLLB d√©j√† pr√©sent dans {nllb_path}\")\n",
                "\n",
                "# 2. Export Opus-MT (Ewe -> Fran√ßais)\n",
                "opus_model_name = \"Helsinki-NLP/opus-mt-ee-fr\"\n",
                "opus_path = settings.PROJECT_ROOT / \"models\" / \"opus-ewe-fr-local\"\n",
                "\n",
                "if not opus_path.exists():\n",
                "    print(f\"T√©l√©chargement de {opus_model_name}...\")\n",
                "    tokenizer = MarianTokenizer.from_pretrained(opus_model_name)\n",
                "    model = MarianMTModel.from_pretrained(opus_model_name)\n",
                "    \n",
                "    print(f\"Sauvegarde dans {opus_path}...\")\n",
                "    model.save_pretrained(opus_path)\n",
                "    tokenizer.save_pretrained(opus_path)\n",
                "else:\n",
                "    print(f\"Mod√®le Opus d√©j√† pr√©sent dans {opus_path}\")\n",
                "\n",
                "print(\"Tous les mod√®les sont pr√™ts localement !\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a5",
            "metadata": {},
            "source": [
                "## 3. Test Audio Complet avec les 3 Mod√®les Export√©s (Local)\n",
                "\n",
                "Nous chargeons maintenant **les 3 mod√®les** uniquement depuis le dossier `models/`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "a6",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1. Chargement du mod√®le ASR local...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:src.pipeline.translate_cascade:Initialisation de la cascade de traduction...\n",
                        "INFO:src.models.translation_mina_ewe:Chargement du mod√®le Mina-Ewe : C:\\EPL\\MTH2321\\MTH_2321_APEKE\\Projet_traduction_ewe_francais\\models\\nllb-mina-ewe-local\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "   OK.\n",
                        "2. Initialisation de la Cascade avec les mod√®les locaux...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "The tokenizer you are loading from 'C:\\EPL\\MTH2321\\MTH_2321_APEKE\\Projet_traduction_ewe_francais\\models\\nllb-mina-ewe-local' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n",
                        "INFO:src.models.translation_ewe_fr:Chargement du mod√®le Transformers C:\\EPL\\MTH2321\\MTH_2321_APEKE\\Projet_traduction_ewe_francais\\models\\opus-ewe-fr-local\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "   OK.\n"
                    ]
                }
            ],
            "source": [
                "# Chemins locaux\n",
                "asr_path = settings.PROJECT_ROOT / \"models\" / \"whisper-ewe-mina-final\"\n",
                "nllb_path = settings.PROJECT_ROOT / \"models\" / \"nllb-mina-ewe-local\"\n",
                "opus_path = settings.PROJECT_ROOT / \"models\" / \"opus-ewe-fr-local\"\n",
                "\n",
                "print(\"1. Chargement du mod√®le ASR local...\")\n",
                "try:\n",
                "    loaded_processor = WhisperProcessor.from_pretrained(asr_path)\n",
                "    loaded_model = WhisperForConditionalGeneration.from_pretrained(asr_path)\n",
                "    print(\"   OK.\")\n",
                "except Exception as e:\n",
                "    print(f\"   Erreur ASR (il faut lancer l'entra√Ænement avant) : {e}\")\n",
                "    # Fallback pour ne pas bloquer si pas entra√Æn√© dans cette session\n",
                "    loaded_processor = processor \n",
                "    loaded_model = model\n",
                "\n",
                "print(\"2. Initialisation de la Cascade avec les mod√®les locaux...\")\n",
                "cascade = TranslationCascade(nllb_path=str(nllb_path), opus_path=str(opus_path))\n",
                "print(\"   OK.\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "cfed416a",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Traitement audio : gegbe_gen_01.wav\n",
                        "Dur√©e originale : 368.40 secondes\n",
                        "√âchantillons    : 5,894,400\n",
                        "Sample rate lu  : 16000 Hz\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:src.pipeline.translate_cascade:Source (Mina):  gone le J√©beho Man …õt…î…õt…ît…î 2gbansihi habe d…îro d…î su hone j√©jai Maod√≥ d…î jynkuti ku annib√£ ayiimala na manh e be le ge bello kyi h√¨ w√¨ t√¨ t√¨r√¨p…î la gone j…î w√¨ d√¨be ap≈´ b√†j…î √† v√≤ma…î h√® b≈ã gb√£n d√¨na sa le se√≤ z√¨f d√¨wo m…î g≈ã manbe k√®ng…î n√® v√®em√© K\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Transcription (ASR) :\n",
                        " gone le J√©beho Man …õt…î…õt…ît…î 2gbansihi habe d…îro d…î su hone j√©jai Maod√≥ d…î jynkuti ku annib√£ ayiimala na manh e be le ge bello kyi h√¨ w√¨ t√¨ t√¨r√¨p…î la gone j…î w√¨ d√¨be ap≈´ b√†j…î √† v√≤ma…î h√® b≈ã gb√£n d√¨na sa le se√≤ z√¨f d√¨wo m…î g≈ã manbe k√®ng…î n√® v√®em√© K\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:src.pipeline.translate_cascade:Pivot (Ewe): dzo le Yebeho Man …õt…ît…ît…ît…î 2gbansihi habe d…îro d…î su hone j√©jai Maod√≥ d…î jynkuti ku annib√£ ayiimala na man e be le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le\n",
                        "INFO:src.pipeline.translate_cascade:Cible (Fran√ßais): √Ä Yeho Mansisihi, dans la ville de Madjal√≥ldoa, on trouve aupr√®s d'Adyjal√≥o, o√π se trouve manitia, dans un quartier situ√© √† proximit√© de chez elle, o√π se trouve une maladie grave.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== R√âSULTAT 100% LOCAL ===\n",
                        "TEXTE (ASR) :  gone le J√©beho Man …õt…î…õt…ît…î 2gbansihi habe d…îro d…î su hone j√©jai Maod√≥ d…î jynkuti ku annib√£ ayiimala na manh e be le ge bello kyi h√¨ w√¨ t√¨ t√¨r√¨p…î la gone j…î w√¨ d√¨be ap≈´ b√†j…î √† v√≤ma…î h√® b≈ã gb√£n d√¨na sa le se√≤ z√¨f d√¨wo m…î g≈ã manbe k√®ng…î n√® v√®em√© K\n",
                        "PIVOT (EWE) : dzo le Yebeho Man …õt…ît…ît…ît…î 2gbansihi habe d…îro d…î su hone j√©jai Maod√≥ d…î jynkuti ku annib√£ ayiimala na man e be le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le\n",
                        "TRAD (FR)   : √Ä Yeho Mansisihi, dans la ville de Madjal√≥ldoa, on trouve aupr√®s d'Adyjal√≥o, o√π se trouve manitia, dans un quartier situ√© √† proximit√© de chez elle, o√π se trouve une maladie grave.\n"
                    ]
                }
            ],
            "source": [
                "# --- INFERENCE ---\n",
                "import soundfile as sf\n",
                "import scipy.signal\n",
                "import numpy as np\n",
                "import torch\n",
                "\n",
                "sample_audio = settings.PROCESSED_DIR / \"audio_16k\" / \"gegbe_gen_01.wav\"\n",
                "\n",
                "if sample_audio.exists():\n",
                "    print(f\"\\nTraitement audio : {sample_audio.name}\")\n",
                "    \n",
                "    waveform, sr = sf.read(sample_audio)\n",
                "    \n",
                "    print(f\"Dur√©e originale : {len(waveform) / sr:.2f} secondes\")\n",
                "    print(f\"√âchantillons    : {len(waveform):,}\")\n",
                "    print(f\"Sample rate lu  : {sr} Hz\")\n",
                "    \n",
                "    # Mono si st√©r√©o\n",
                "    if len(waveform.shape) > 1:\n",
                "        waveform = waveform.mean(axis=1)\n",
                "        \n",
                "    # Resample si besoin\n",
                "    if sr != 16000:\n",
                "        num_samples = int(round(len(waveform) * 16000 / sr))\n",
                "        waveform = scipy.signal.resample(waveform, num_samples)\n",
                "    \n",
                "    # Pr√©paration Whisper\n",
                "    input_features = loaded_processor(\n",
                "        waveform,\n",
                "        sampling_rate=16000,\n",
                "        return_tensors=\"pt\"\n",
                "    ).input_features\n",
                "    \n",
                "    # Tr√®s important : d√©placer sur le bon device (GPU si disponible)\n",
                "    device = next(loaded_model.parameters()).device\n",
                "    input_features = input_features.to(device)\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        predicted_ids = loaded_model.generate(\n",
                "            input_features,\n",
                "            language=None,                     # ou \"mina\" / None si d√©tection auto\n",
                "            task=\"transcribe\",\n",
                "            return_timestamps=True,             # active le d√©coupage automatique 30s + stitching\n",
                "            condition_on_prev_tokens=True,\n",
                "            temperature=[0.0, 0.2, 0.4, 0.6, 0.8, 1.0],  # fallback si r√©p√©titions/hallucinations\n",
                "            compression_ratio_threshold=1.35,\n",
                "            logprob_threshold=-1.0,\n",
                "            no_speech_threshold=0.6,\n",
                "        )\n",
                "    \n",
                "    transcription = loaded_processor.batch_decode(\n",
                "        predicted_ids,\n",
                "        skip_special_tokens=True\n",
                "    )[0]\n",
                "    \n",
                "    print(f\"\\nTranscription (ASR) :\\n{transcription}\\n\")\n",
                "    \n",
                "    final_result = cascade.translate_mina_to_french(transcription)\n",
                "    \n",
                "    print(\"=== R√âSULTAT 100% LOCAL ===\")\n",
                "    print(f\"TEXTE (ASR) : {final_result['mina']}\")\n",
                "    print(f\"PIVOT (EWE) : {final_result['ewe']}\")\n",
                "    print(f\"TRAD (FR)   : {final_result['french']}\")\n",
                "\n",
                "else:\n",
                "    print(\"Fichier audio non trouv√©.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9ec0367f",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
